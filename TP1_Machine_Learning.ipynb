{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><i>\n",
    "<font color=\"dodgerblue\" style=\"font-family:cursive; font-size:18px;\"><h1>TP 1 : NB / SVM / Neural Network</h1></font></i>\n",
    "</center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Lien Pour TP N°1 : Data Preparation (Google Colab)](https://colab.research.google.com/drive/1-oT7l5lkidI0VVRnKQ9oGPcykuVfs5pq?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b><i><font color=\"tomato\">I -Packages Importation:</font></i></b></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"font-family:cursive;\">\n",
    "<blockquote>\n",
    "<i><font style=\"background-color:#ffabaf;\"><b>pandas:</b></font>  est une bibliothèque écrite pour le langage de programmation Python permettant la manipulation et l'analyse des données. Elle propose en particulier des structures de données et des opérations de manipulation de tableaux numériques et de séries temporelles.</i>\n",
    "<br/>\n",
    "<br/>\n",
    "<i><font style=\"background-color:#ffabaf;\"><b>sklearn: </b></font>Scikit-learn est la principale bibliothèque d'outils dédiés au machine learning et à la data-science dans l'univers Python</i>\n",
    "<blockquote>\n",
    "    <i><font style=\"background-color:#ffabaf;\"><b>train_test_split: </b></font>Dès que on a un apprentissage automatisé, Nous avon besoin de manipuler plusieurs ensembles. Nous allons découper l'ensemble labellisé en plusieurs sous-ensembles :</i><br/>\n",
    "    <ul>\n",
    "    <li><i>Un ensemble d'entraînement pour entraîner nos modèles de machine learning.</i></li>\n",
    "    <li><i>Un ensemble de test pour mesurer la performance de nos modèles sur des données non apprises. La performance d'un modèle sur l'ensemble de test correspond à une mesure de ce modèle sur des données réelles, qui permettent d'évaluer la capacité de généralisation du modèle.</i></li>\n",
    "    </ul>\n",
    "    <i>Il est nécessaire que tous les ensembles que nous manipulons soient représentatifs du cas à modéliser sans quoi nous allons tester le modèle sur des données qui ne correspondent pas aux données d'entraînement. C'est pourquoi nous devons assurer que les distributions de tous ces ensembles sont comparables. Généralement on réalise des coupes aléatoires dans le dataset pour déterminer les sous-ensembles.</i>\n",
    "    <br/><br/>\n",
    "    <i><font style=\"background-color:#ffabaf;\"><b>Naive Bayes:</b></font></i> La classification naïve bayésienne est un type de classification bayésienne probabiliste simple basée sur le théorème de Bayes avec une forte indépendance des hypothèses.\n",
    "    <br/><br/>\n",
    "    <i><font style=\"background-color:#ffabaf;\"><b>SVM (Support Vector Machine ou Machine à vecteurs de support):</b></font> Les SVMs sont une famille d’algorithmes d‘apprentissage automatique qui permettent de résoudre des problèmes tant de classification que de régression ou de détection d’anomalie.</i>\n",
    "    <br/><br/>\n",
    "    <i><font style=\"background-color:#ffabaf;\"><b>Les réseaux de neurones:</b></font> profonds représentent en réalité le dernier maillon dans l’évolution de l’intelligence artificielle. À l’origine, le Machine Learning permet d’automatiser les modèles statistiques par le biais d’algorithmes pour réaliser de meilleures prédictions.</i>\n",
    "    <br/><br/>\n",
    "   <i><font style=\"background-color:#ffabaf;\"><b>metrics:</b></font> pour évaluer les performances de notre modéle.</i>\n",
    "</blockquote>\n",
    "    </blockquote>\n",
    "       </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # pandas is used to read files of the datasets\n",
    "from sklearn.model_selection import train_test_split # train_test_split is used to part\n",
    "from sklearn.naive_bayes import GaussianNB # GaussianNB() is the naive bayes classifier\n",
    "from sklearn.svm import SVC # SVC() is the Support Vector Machines Classifier\n",
    "from sklearn.neural_network import MLPClassifier # MLPClassifier us the Neural Network\n",
    "from sklearn.metrics import confusion_matrix, classification_report # Confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b><i><font color=\"tomato\">II -Dataset Preparation:</font></i></b></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame's shape :  (1372, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variance</th>\n",
       "      <th>Skewness</th>\n",
       "      <th>Curtosis</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.6661</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.1674</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.6383</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.5228</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.4552</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Variance  Skewness  Curtosis  Entropy  Class\n",
       "0   3.62160    8.6661   -2.8073 -0.44699      0\n",
       "1   4.54590    8.1674   -2.4586 -1.46210      0\n",
       "2   3.86600   -2.6383    1.9242  0.10645      0\n",
       "3   3.45660    9.5228   -4.0112 -3.59440      0\n",
       "4   0.32924   -4.4552    4.5718 -0.98880      0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('bill_authentication.csv') # Read the dataset in a new data frame(df)\n",
    "print(\"DataFrame's shape : \", df.shape)\n",
    "df.head() # Display the first five rows (5 premières lignes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variance</th>\n",
       "      <th>Skewness</th>\n",
       "      <th>Curtosis</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>0.40614</td>\n",
       "      <td>1.34920</td>\n",
       "      <td>-1.4501</td>\n",
       "      <td>-0.55949</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368</th>\n",
       "      <td>-1.38870</td>\n",
       "      <td>-4.87730</td>\n",
       "      <td>6.4774</td>\n",
       "      <td>0.34179</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>-3.75030</td>\n",
       "      <td>-13.45860</td>\n",
       "      <td>17.5932</td>\n",
       "      <td>-2.77710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>-3.56370</td>\n",
       "      <td>-8.38270</td>\n",
       "      <td>12.3930</td>\n",
       "      <td>-1.28230</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>-2.54190</td>\n",
       "      <td>-0.65804</td>\n",
       "      <td>2.6842</td>\n",
       "      <td>1.19520</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Variance  Skewness  Curtosis  Entropy  Class\n",
       "1367   0.40614   1.34920   -1.4501 -0.55949      1\n",
       "1368  -1.38870  -4.87730    6.4774  0.34179      1\n",
       "1369  -3.75030 -13.45860   17.5932 -2.77710      1\n",
       "1370  -3.56370  -8.38270   12.3930 -1.28230      1\n",
       "1371  -2.54190  -0.65804    2.6842  1.19520      1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail() # Display the last five rows (5 dernières lignes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"font-family:cursive;\"><i>Nous séparerons les échantillons et leurs classes.</i></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variance</th>\n",
       "      <th>Skewness</th>\n",
       "      <th>Curtosis</th>\n",
       "      <th>Entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.6661</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.1674</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.6383</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.5228</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.4552</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Variance  Skewness  Curtosis  Entropy\n",
       "0   3.62160    8.6661   -2.8073 -0.44699\n",
       "1   4.54590    8.1674   -2.4586 -1.46210\n",
       "2   3.86600   -2.6383    1.9242  0.10645\n",
       "3   3.45660    9.5228   -4.0112 -3.59440\n",
       "4   0.32924   -4.4552    4.5718 -0.98880"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=df.drop('Class',axis=1)\n",
    "y=df['Class']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "[X_train,X_test,y_train,y_test]=train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 1097/1372\n",
      "Test dataset size: 275/1372\n"
     ]
    }
   ],
   "source": [
    "print(\"Train dataset size: {}/{}\".format(len(X_train),len(y)))\n",
    "print(\"Test dataset size: {}/{}\".format(len(X_test),len(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b><i><font color=\"tomato\">III -Machine Learning: NB Vs SVM Vs Neural Network:</font></i></b></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><h3><font style=\"font-family:cursive\">Naive Bayes</font></h3></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb=GaussianNB() # gnb is a naive bayes classifier\n",
    "gnb.fit(X_train,y_train) # Train Guassian NB classifier\n",
    "y_nb=gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><h3><font style=\"font-family:cursive\">SVM Lineair</font></h3></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_svm =SVC(kernel='linear') # linear_svm is a Linear Support Vectors\n",
    "linear_svm.fit(X_train,y_train) # Train SVM\n",
    "y_linear_svm=linear_svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><h3><font style=\"font-family:cursive\">Les autres algorithmes :</font></h3></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_svm=SVC(kernel='rbf')# rbf_svm is a RBF support vectors\n",
    "sigmoid_svm =SVC(kernel='sigmoid')# sigmoid support vectors\n",
    "ploy_svm=SVC(kernel='poly',degree=2) # Ploynom with degree=2 as support vectors\n",
    "neural=MLPClassifier(hidden_layer_sizes=(100,20),activation='relu',solver='adam') # neu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(100, 20), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbf_svm.fit(X_train,y_train)\n",
    "sigmoid_svm.fit(X_train,y_train)\n",
    "ploy_svm.fit(X_train,y_train)\n",
    "neural.fit(X_train,y_train) # Train Neural Network - finding the best weight matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hadhemi\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:749: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y = np.array(y > threshold, dtype=np.int)\n"
     ]
    }
   ],
   "source": [
    "y_rbf_svm=rbf_svm.predict(X_test)\n",
    "y_ploy_svm=ploy_svm.predict(X_test)\n",
    "y_sigmoid_svm=sigmoid_svm.predict(X_test)\n",
    "y_neural=neural.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b><i><font color=\"tomato\">IV -Performance Evaluation:</font></i></b></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* Peformance Evauation of Naive Bayes **************\n",
      "[[129  22]\n",
      " [ 28  96]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.84       151\n",
      "           1       0.81      0.77      0.79       124\n",
      "\n",
      "    accuracy                           0.82       275\n",
      "   macro avg       0.82      0.81      0.82       275\n",
      "weighted avg       0.82      0.82      0.82       275\n",
      "\n",
      "************* Peformance Evauation of Linear SVM **************\n",
      "[[148   3]\n",
      " [  2 122]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       151\n",
      "           1       0.98      0.98      0.98       124\n",
      "\n",
      "    accuracy                           0.98       275\n",
      "   macro avg       0.98      0.98      0.98       275\n",
      "weighted avg       0.98      0.98      0.98       275\n",
      "\n",
      "************* Peformance Evauation of RBF SVM **************\n",
      "[[151   0]\n",
      " [  0 124]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       151\n",
      "           1       1.00      1.00      1.00       124\n",
      "\n",
      "    accuracy                           1.00       275\n",
      "   macro avg       1.00      1.00      1.00       275\n",
      "weighted avg       1.00      1.00      1.00       275\n",
      "\n",
      "************* Peformance Evauation of Sigmoid SVM **************\n",
      "[[100  51]\n",
      " [ 58  66]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.66      0.65       151\n",
      "           1       0.56      0.53      0.55       124\n",
      "\n",
      "    accuracy                           0.60       275\n",
      "   macro avg       0.60      0.60      0.60       275\n",
      "weighted avg       0.60      0.60      0.60       275\n",
      "\n",
      "************* Peformance Evauation of Polynomial (2) SVM **************\n",
      "[[149   2]\n",
      " [  0 124]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       151\n",
      "           1       0.98      1.00      0.99       124\n",
      "\n",
      "    accuracy                           0.99       275\n",
      "   macro avg       0.99      0.99      0.99       275\n",
      "weighted avg       0.99      0.99      0.99       275\n",
      "\n",
      "************* Peformance Evauation of Neural Network **************\n",
      "[[151   0]\n",
      " [  0 124]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       151\n",
      "           1       1.00      1.00      1.00       124\n",
      "\n",
      "    accuracy                           1.00       275\n",
      "   macro avg       1.00      1.00      1.00       275\n",
      "weighted avg       1.00      1.00      1.00       275\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print ('************* Peformance Evauation of Naive Bayes **************')\n",
    "print(confusion_matrix(y_test,y_nb))\n",
    "print(classification_report(y_test,y_nb))\n",
    "print ('************* Peformance Evauation of Linear SVM **************')\n",
    "print(confusion_matrix(y_test,y_linear_svm))\n",
    "print(classification_report(y_test,y_linear_svm))\n",
    "print ('************* Peformance Evauation of RBF SVM **************')\n",
    "print(confusion_matrix(y_test,y_rbf_svm))\n",
    "print(classification_report(y_test,y_rbf_svm))\n",
    "print ('************* Peformance Evauation of Sigmoid SVM **************')\n",
    "print(confusion_matrix(y_test,y_sigmoid_svm))\n",
    "print(classification_report(y_test,y_sigmoid_svm))\n",
    "print ('************* Peformance Evauation of Polynomial (2) SVM **************')\n",
    "print(confusion_matrix(y_test,y_ploy_svm))\n",
    "print(classification_report(y_test,y_ploy_svm))\n",
    "print ('************* Peformance Evauation of Neural Network **************')\n",
    "print(confusion_matrix(y_test,y_neural))\n",
    "print(classification_report(y_test,y_neural))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><h4><font style=\"font-family:cursive\">Nous choisissons SVM Linear car c'est le plus efficace pour nos Datasets.\n",
    "</font></h3></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
